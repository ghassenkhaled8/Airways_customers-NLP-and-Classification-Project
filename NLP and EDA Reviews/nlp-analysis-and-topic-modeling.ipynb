{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":30.634607,"end_time":"2022-12-19T10:50:21.870242","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-12-19T10:49:51.235635","version":"2.3.4"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5386561,"sourceType":"datasetVersion","datasetId":2914207}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from nltk.corpus import stopwords\nimport matplotlib.pyplot as plt\nfrom nltk.tokenize import word_tokenize\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nfrom string import digits\nimport requests\nimport pandas as pd\nimport nltk\nimport string\nimport seaborn as sns\nimport re\nnltk.download(\"stopwords\")\nstop_words = set(stopwords.words('english'))","metadata":{"papermill":{"duration":2.633256,"end_time":"2022-12-19T10:50:03.393900","exception":false,"start_time":"2022-12-19T10:50:00.760644","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-26T13:00:05.064376Z","iopub.execute_input":"2023-11-26T13:00:05.065076Z","iopub.status.idle":"2023-11-26T13:00:08.694315Z","shell.execute_reply.started":"2023-11-26T13:00:05.065041Z","shell.execute_reply":"2023-11-26T13:00:08.693013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Saving the reviews in a data frame","metadata":{"papermill":{"duration":0.006463,"end_time":"2022-12-19T10:50:16.764882","exception":false,"start_time":"2022-12-19T10:50:16.758419","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"#### TASK 1\n#### Data Loading for a different method","metadata":{}},{"cell_type":"code","source":"# Read a CSV file into a DataFrame using the read_csv function from pandas\n# The file path \"/kaggle/input/airways-customer-data/airline_data.csv\" is specified\ndf=pd.read_csv(\"/kaggle/input/airways-customer-data/airline_data.csv\")\ndf.head() # Display the first few rows (default is 5 rows) of the DataFrame using the head() method","metadata":{"papermill":{"duration":0.047638,"end_time":"2022-12-19T10:50:16.819188","exception":false,"start_time":"2022-12-19T10:50:16.771550","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-26T13:00:08.697852Z","iopub.execute_input":"2023-11-26T13:00:08.698656Z","iopub.status.idle":"2023-11-26T13:00:08.871275Z","shell.execute_reply.started":"2023-11-26T13:00:08.698621Z","shell.execute_reply":"2023-11-26T13:00:08.870108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Saving the dataframe in csv file ","metadata":{"papermill":{"duration":0.008482,"end_time":"2022-12-19T10:50:16.834791","exception":false,"start_time":"2022-12-19T10:50:16.826309","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df.to_csv(\"BA_reviews.csv\") # Save the DataFrame 'df' to a CSV file named \"BA_reviews.csv\"\n# The to_csv() method is used to export the DataFrame to a CSV file","metadata":{"papermill":{"duration":0.040889,"end_time":"2022-12-19T10:50:16.882659","exception":false,"start_time":"2022-12-19T10:50:16.841770","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-26T13:00:08.873033Z","iopub.execute_input":"2023-11-26T13:00:08.873606Z","iopub.status.idle":"2023-11-26T13:00:09.063977Z","shell.execute_reply.started":"2023-11-26T13:00:08.873566Z","shell.execute_reply":"2023-11-26T13:00:09.062744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### TASK 2\n#### Data cleaning","metadata":{"papermill":{"duration":0.007579,"end_time":"2022-12-19T10:50:16.897452","exception":false,"start_time":"2022-12-19T10:50:16.889873","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\n\ncsv_path = \"BA_reviews.csv\" # Specify the file path for the CSV file containing the reviews data\n\ndf1 = pd.read_csv(csv_path) # Read the CSV file into a DataFrame using the read_csv function from pandas\n\ndf1.reset_index(drop=True, inplace=True) # Reset the index of the DataFrame. drop=True removes the old index column.\n# inplace=True modifies the DataFrame in place, without creating a new object.\n\nprint(df1['reviews']) # Print the 'reviews' column of the DataFrame\n","metadata":{"papermill":{"duration":0.040066,"end_time":"2022-12-19T10:50:16.944677","exception":false,"start_time":"2022-12-19T10:50:16.904611","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-26T13:00:09.067745Z","iopub.execute_input":"2023-11-26T13:00:09.068245Z","iopub.status.idle":"2023-11-26T13:00:09.135159Z","shell.execute_reply.started":"2023-11-26T13:00:09.068198Z","shell.execute_reply":"2023-11-26T13:00:09.133886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display concise summary information about the DataFrame df1\n# The info() method provides information such as data types, non-null values, and memory usage\ndf1.info()\n# Generate descriptive statistics of the DataFrame df1\n# The describe() method gives statistics like mean, standard deviation, min, and max for numeric columns\ndf1.describe()","metadata":{"papermill":{"duration":0.045666,"end_time":"2022-12-19T10:50:16.998074","exception":false,"start_time":"2022-12-19T10:50:16.952408","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-26T13:00:09.136824Z","iopub.execute_input":"2023-11-26T13:00:09.137281Z","iopub.status.idle":"2023-11-26T13:00:09.192369Z","shell.execute_reply.started":"2023-11-26T13:00:09.137242Z","shell.execute_reply":"2023-11-26T13:00:09.191371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no null values/ missing values in out dataset.\nThe dataset contains 1000 unique entries.\nRemoving (✅ Trip Verified | and Not Verified | ) to clean the data.\nRemoving any leading or trailing spaces.\nTurning the review string to all lower case.\n","metadata":{"papermill":{"duration":0.00748,"end_time":"2022-12-19T10:50:17.013176","exception":false,"start_time":"2022-12-19T10:50:17.005696","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Remove leading and trailing whitespaces from the 'reviews' column in DataFrame df1\ndf1['reviews'] = df1['reviews'].str.strip()\n# Remove the prefix '✅ Trip Verified |' from the beginning of each entry in the 'reviews' column\ndf1['reviews']=df1['reviews'].str.lstrip('✅ Trip Verified |')\n# Remove the prefix 'Not Verified |' from the beginning of each entry in the 'reviews' column\ndf1['reviews']=df1['reviews'].str.lstrip('Not Verified |')\n# Convert all characters in the 'reviews' column to lowercase\ndf1['reviews']= df1['reviews'].str.lower()\n# Print the modified DataFrame\nprint(df1)","metadata":{"papermill":{"duration":0.028975,"end_time":"2022-12-19T10:50:17.049989","exception":false,"start_time":"2022-12-19T10:50:17.021014","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-26T13:00:09.193711Z","iopub.execute_input":"2023-11-26T13:00:09.194558Z","iopub.status.idle":"2023-11-26T13:00:09.237558Z","shell.execute_reply.started":"2023-11-26T13:00:09.194524Z","shell.execute_reply":"2023-11-26T13:00:09.236209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TASK 3\n#### Sentiment analysis of reviews using nltk ","metadata":{"papermill":{"duration":0.007381,"end_time":"2022-12-19T10:50:17.065253","exception":false,"start_time":"2022-12-19T10:50:17.057872","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Remove punctutaions","metadata":{"papermill":{"duration":0.007176,"end_time":"2022-12-19T10:50:17.080132","exception":false,"start_time":"2022-12-19T10:50:17.072956","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#remove punctuation\n# Replace all non-alphanumeric characters and whitespace in the 'reviews' column with an empty string\n# The regular expression '[^\\w\\s]' matches any character that is not a word character (alphanumeric) or whitespace\ndf1['reviews'] = df1['reviews'].str.replace('[^\\w\\s]','')\n# Print the modified 'reviews' column in the DataFrame df1\nprint(df1['reviews'])","metadata":{"papermill":{"duration":0.037491,"end_time":"2022-12-19T10:50:17.125169","exception":false,"start_time":"2022-12-19T10:50:17.087678","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-26T13:00:09.239119Z","iopub.execute_input":"2023-11-26T13:00:09.239554Z","iopub.status.idle":"2023-11-26T13:00:09.254900Z","shell.execute_reply.started":"2023-11-26T13:00:09.239516Z","shell.execute_reply":"2023-11-26T13:00:09.253772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tokenize the review column","metadata":{"papermill":{"duration":0.008105,"end_time":"2022-12-19T10:50:17.141990","exception":false,"start_time":"2022-12-19T10:50:17.133885","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# tokenize\n# Print the content of the 'reviews' column for the second row (index 1) and second column (index 1) using iloc\nprint(df1.iloc[1,1])\n# Tokenize each entry in the 'reviews' column using NLTK's word_tokenize function\n# The lambda function is applied to each row using the apply() method along the specified axis\ndf1['reviews'] = df1.apply(lambda row: nltk.word_tokenize(row['reviews']), axis=1)\n# Print the tokenized content of the 'reviews' column for the first row (index 0) and second column (index 1) using iloc\nprint(df1.iloc[0,1])","metadata":{"papermill":{"duration":0.590186,"end_time":"2022-12-19T10:50:17.740215","exception":false,"start_time":"2022-12-19T10:50:17.150029","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-26T13:00:09.256635Z","iopub.execute_input":"2023-11-26T13:00:09.257326Z","iopub.status.idle":"2023-11-26T13:00:18.266575Z","shell.execute_reply.started":"2023-11-26T13:00:09.257285Z","shell.execute_reply":"2023-11-26T13:00:18.265410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Removing stopwords","metadata":{"papermill":{"duration":0.007748,"end_time":"2022-12-19T10:50:17.756211","exception":false,"start_time":"2022-12-19T10:50:17.748463","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Apply a lambda function to the 'reviews' column to remove stop words\n# The lambda function uses a list comprehension to filter out stop words from each entry\n# The filtered words are then joined into a space-separated string\ndf1['reviews'] = df1['reviews'].apply(lambda x: ' '.join([word for word in x if word not in (stop_words)]))\n# Print the first 20 rows of the modified DataFrame\nprint(df1.head(20))","metadata":{"papermill":{"duration":0.049074,"end_time":"2022-12-19T10:50:17.813343","exception":false,"start_time":"2022-12-19T10:50:17.764269","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-26T13:00:18.267804Z","iopub.execute_input":"2023-11-26T13:00:18.268131Z","iopub.status.idle":"2023-11-26T13:00:18.391503Z","shell.execute_reply.started":"2023-11-26T13:00:18.268103Z","shell.execute_reply":"2023-11-26T13:00:18.390350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Calculate polarity to gather sentiment tags.","metadata":{"papermill":{"duration":0.007998,"end_time":"2022-12-19T10:50:17.831267","exception":false,"start_time":"2022-12-19T10:50:17.823269","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Define a function to calculate the polarity of a given text using TextBlob\ndef polarity_calc(text):\n    try:\n        return TextBlob(text).sentiment.polarity\n    except:\n        return None\n    \n# Define a function to assign a sentiment tag based on the calculated polarity\ndef tag_cal(num):\n    if num<0:\n        return 'Negative'\n    elif num>0:\n        return 'Positive'\n    else:\n        return 'Neutral'\n        \n# Apply the polarity_calc function to the 'reviews' column and create a new 'polarity' column  \ndf1['polarity'] = df1['reviews'].apply(polarity_calc)\n\n# Apply the tag_cal function to the 'polarity' column and create a new 'tag' column\ndf1['tag'] = df1['polarity'].apply(tag_cal)\n\n# Print the DataFrame with the new 'polarity' and 'tag' columns\nprint(df1)","metadata":{"papermill":{"duration":0.963725,"end_time":"2022-12-19T10:50:18.803270","exception":false,"start_time":"2022-12-19T10:50:17.839545","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-26T13:00:18.394806Z","iopub.execute_input":"2023-11-26T13:00:18.395194Z","iopub.status.idle":"2023-11-26T13:00:22.590666Z","shell.execute_reply.started":"2023-11-26T13:00:18.395152Z","shell.execute_reply":"2023-11-26T13:00:22.588881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TASK 4 \n#### Analyze ","metadata":{"papermill":{"duration":0.00842,"end_time":"2022-12-19T10:50:18.824621","exception":false,"start_time":"2022-12-19T10:50:18.816201","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"The percentage of various types of tags.\n","metadata":{"papermill":{"duration":0.008204,"end_time":"2022-12-19T10:50:18.841429","exception":false,"start_time":"2022-12-19T10:50:18.833225","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Group the DataFrame df1 by the 'tag' column and calculate the percentage distribution of each sentiment tag\n# The size() method counts the occurrences of each tag, and the result is divided by the total count of tags\n# The result is multiplied by 100 to get the percentage distribution\n(df1.groupby('tag').size()/df1['tag'].count())*100","metadata":{"papermill":{"duration":0.030332,"end_time":"2022-12-19T10:50:18.880239","exception":false,"start_time":"2022-12-19T10:50:18.849907","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-26T13:00:22.592718Z","iopub.execute_input":"2023-11-26T13:00:22.593228Z","iopub.status.idle":"2023-11-26T13:00:22.606050Z","shell.execute_reply.started":"2023-11-26T13:00:22.593181Z","shell.execute_reply":"2023-11-26T13:00:22.604643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of each kind of reviews","metadata":{"papermill":{"duration":0.008387,"end_time":"2022-12-19T10:50:18.897442","exception":false,"start_time":"2022-12-19T10:50:18.889055","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## TASK 5\n#### Visualizing the results","metadata":{"papermill":{"duration":0.008381,"end_time":"2022-12-19T10:50:18.914343","exception":false,"start_time":"2022-12-19T10:50:18.905962","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Initialize an empty string 'text' to concatenate positive reviews\ntext = \" \"\n\n# Iterate over the DataFrame indices\nfor ind in df1.index:\n    # Check if the sentiment tag is \"Positive\"\n    if df1['tag'][ind] == \"Positive\":\n        # Concatenate the positive review to the 'text' string\n        text = text + df1['reviews'][ind]\n# Generate a WordCloud from the concatenated positive reviews        \n      \nwordcloud_positive = WordCloud().generate(text)\n\n# Display the generated WordCloud image\n# Display the generated image:\nplt.imshow(wordcloud_positive, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()\n","metadata":{"papermill":{"duration":1.023841,"end_time":"2022-12-19T10:50:19.946813","exception":false,"start_time":"2022-12-19T10:50:18.922972","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-26T13:00:22.607868Z","iopub.execute_input":"2023-11-26T13:00:22.608806Z","iopub.status.idle":"2023-11-26T13:00:25.730867Z","shell.execute_reply.started":"2023-11-26T13:00:22.608579Z","shell.execute_reply":"2023-11-26T13:00:25.729677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize an empty string 'text2' to concatenate negative reviews\ntext2= \" \"        \n# Iterate over the DataFrame indices\nfor ind in df1.index:\n    # Check if the sentiment tag is \"Negative\"\n    if df1['tag'][ind] == \"Negative\":\n        # Concatenate the negative review to the 'text2' string\n        text2 = text2 + df1['reviews'][ind]  \n# Generate a WordCloud from the concatenated negative reviews\nwordcloud_negative = WordCloud().generate(text2)\n# Display the generated WordCloud image for negative reviews\nplt.imshow(wordcloud_negative, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","metadata":{"papermill":{"duration":0.674866,"end_time":"2022-12-19T10:50:20.632979","exception":false,"start_time":"2022-12-19T10:50:19.958113","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-26T13:00:25.732071Z","iopub.execute_input":"2023-11-26T13:00:25.732482Z","iopub.status.idle":"2023-11-26T13:00:27.321085Z","shell.execute_reply.started":"2023-11-26T13:00:25.732447Z","shell.execute_reply":"2023-11-26T13:00:27.319537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot a bar chart of the sentiment tag counts using Matplotlib and Seaborn\n# The value_counts() method counts the occurrences of each sentiment tag\n# The plot() method with kind='bar' is used to create a bar chart\ndf1['tag'].value_counts().plot(kind='bar')\n# Set the font scale for better readability\nsns.set(font_scale=1.4)\n# Plot the bar chart with specified figure size, rotation, and labels\ndf1['tag'].value_counts().plot(kind='bar', figsize=(7, 6), rot=0)\nplt.xlabel(\"Sentiment\", labelpad=14)\nplt.ylabel(\"No of reviews\", labelpad=14)\nplt.title(\"Sentient counts\", y=1.02);","metadata":{"papermill":{"duration":0.286556,"end_time":"2022-12-19T10:50:20.931981","exception":false,"start_time":"2022-12-19T10:50:20.645425","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-26T13:00:27.323845Z","iopub.execute_input":"2023-11-26T13:00:27.325030Z","iopub.status.idle":"2023-11-26T13:00:27.640344Z","shell.execute_reply.started":"2023-11-26T13:00:27.324968Z","shell.execute_reply":"2023-11-26T13:00:27.639090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\n\n# Combine all reviews into a single string\nall_reviews = ' '.join(df1['reviews'])\n\n# Create a CountVectorizer object\nvectorizer = CountVectorizer(max_features=1000, stop_words='english')\n\n# Fit and transform the reviews data into a document-term matrix\ndtm = vectorizer.fit_transform(df1['reviews'])\n\n# Initialize the LDA model\nlda = LatentDirichletAllocation(n_components=5, random_state=42)\n\n# Fit the LDA model on the document-term matrix\nlda.fit(dtm)\n\n# Display the top words for each topic\nfeature_names = vectorizer.get_feature_names_out()\nfor index, topic in enumerate(lda.components_):\n    print(f\"\\nTop words for Topic #{index + 1}:\")\n    print([feature_names[i] for i in topic.argsort()[-10:]])\n\n# Transform the document-term matrix into topic probabilities\ntopic_results = lda.transform(dtm)\n\n# Add the topic probabilities to the DataFrame\nfor i in range(lda.n_components):\n    df1[f'Topic_{i + 1}_Prob'] = topic_results[:, i]\n\n# Display the DataFrame with topic probabilities\nprint(df1.head())\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:14:45.291612Z","iopub.execute_input":"2023-11-26T13:14:45.292021Z"},"trusted":true},"execution_count":null,"outputs":[]}]}